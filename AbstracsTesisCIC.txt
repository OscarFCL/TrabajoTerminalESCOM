TESIS - 28082 Aprendizaje de reglas para operar en el mercado accionario

El incremento en el poder de cómputo, la digitalización de los mercados financieros y la oportunidad de obtener grandes ganancias, son algunos de los factores que han motivado la investigación y desarrollo de algoritmos computacionales enfocados a guiar la toma de decisiones de inversión. En particular, se busca que estos algoritmos sean capaces de determinar los momentos adecuados para realizar compras o ventas de un activo financiero. En este trabajo se propone una metodología para aprender, de manera automática, un conjunto de reglas de la forma si...entonces, las cuales nos permitirán generar un conjunto de estrategias de inversión. Estas estrategias serán probadas utilizando datos del mercado accionario mexicano y estadounidense. Además, desde el punto de vista de la teoría económica, este trabajo investiga la hipótesis del mercado eficiente en su versión débil.

TESIS - 28081 Hybrid neural networks with morphological neurons and perceptrons

En el área de Aprendizaje de Máquina (Machine Learning (ML)) existen diversas arquitecturas de redes neuronales. Arquitecturas que por décadas han utilizado las mismas unidades de cómputo para la clasificación de patrones. Dentro de estas unidades encontramos al perceptron y las neuronas morfológicas. Debido a su sustento teórico y resultados prácticos, el perceptron es el elemento más utilizado en arquitecturas de redes neuronales, como lo son las redes neuronales multicapa, profundas, convolucionales, entre otras. Sin embargo, se ha demostrado que el entrenamiento de redes neuronales que incluyen perceptrones poseen varias desventajas, como lo son, un alto número de parámetros de entrenamiento, algoritmos de entrenamiento muy lentos Wilson and Martinez [56], y que los hiperplanos generados por estas unidades de cómputo no son los ideales Glorot and Bengio [14], Bouzerdoum [8]. En este trabajo nos enfocamos en investigar nuevas y diferentes unidades de cómputo las cuales nos permitan reducir la complejidad de los modelos de redes neuronales, reducir los tiempos de entrenamiento y mejorar los hiperplanos generados por dichos modelos. Con lo anterior, se proponen dos nuevas arquitecturas de redes neuronales híbridas, las cuales combinan perceptrones y neuronas morfológicas. La primer arquitectura es la Red Neuronal Lineal-Morfológica, y la segunda Red Neuronal Morfológica-Lineal (LMNN y MLNN por sus siglas en ingles). Ambas arquitecturas se entrenan mediante Descenso de Gradiente Estocástico (SGD) por sus siglas en ingles. Como primer resultado de nuestra investigación se demuestra que una sola capa de neuronas morfológicas posee una mayor capacidad de segmentar el espacio 2D en distintas regiones que una capa de perceptrones. El segundo resultado muestra que es posible utilizar neuronas morfológicas como extractores de rasgos y que, en promedio, esta arquitectura, requiere un menor número de parámetros de entrenamiento que sus contrapartes, y a la vez obtiene mejores porcentajes de clasificación. 

TESIS - 28079 Contributions to the study of neural networks with dendritic processing new training algorithms and new models

Una red morfológica dendral es un tipo de red neuronal la cual puede ser utilizada para resolver problemas de clasificación. La principal diferencia entre ésta y una típica red neuronal es que la red neuronal genera híper planos para dividir en el espacio de búsqueda y la red dendral crea híper cajas. Se ha reportado que las redes dendrales han obtenido igual o mejores resultados que los Perceptrones multi-capa y tienen la ventaja de ser fácilmente implementadas en dispositivos embebidos. Estas peculiaridades motivaron nuestro interés para estudiar éste tipo de redes. Esta tesis se enfocó al mejoramiento de los métodos actuales de entrenamiento y la creación de nuevos modelos neuronales capaces de generar fronteras de decisión más suaves para redes dendrales. El primer enfoque de la tesis fue utilizar evolución diferencial para posicionar las híper cajas formadas por las redes dendrales. El desempeño de este método de entrenamiento fue evaluado experimentalmente utilizando cuatro bases de datos sintéticas y 12 de la Universidad de Irvine, California. Como resultado obtuvimos que el método de entrenamiento propuesto superó a los métodos actuales para entrenar a redes dendrales y a una red radial base. Además, la red dendral entrenada con evolución diferencial presentó resultados competitivos comparados con Perceptrones multi-capa y una máquina vector soporte. Por último, implementamos la red dendral entrenada con evolución diferencial en un robot Nao para hacer reconocimiento de figuras geométricas. En el segundo enfoque propusimos una neurona dendrítica elipsoidal. La diferencia principal entre estas redes dendrales radica en la forma de generar las fronteras de decisión. Para probar el desempeño de la red elipsoidal utilizamos las mismas bases de datos anteriores. La red propuesta obtuvo un porcentaje de clasificación de 80.7%, un Peceptron multi-capa 78.4%, una maquina vector soporte 74.2% y una red radial base 72.7%. Por último, implementamos la red elipsoidal para resolver problemas reales, como: detección de líneas en autopistas, clasificación de figuras geometrías en un robot Nao y en la detección de tráfico. La red elipsoidal mostró tener un buen desempeño en base de datos de baja dimensión, que requiere de pocos parámetros de entrenamiento y que se puede implementar muy fácilmente en dispositivos embebidos. Sin embargo, su principal desventaja es la baja precisión de clasificación con base de datos de altas dimensiones. Después, resolvimos éste problema entrenando la red mediante gradiente descendiente estocástico implementándola como una capa en Keras. Finalmente, obtuvimos una base de datos de alta dimensión de señales electroencefalográficas de movimientos imaginados y resultados competitivos comparados con una máquina vector soporte y un Perceptron multi-capa. 

TESIS - 28036 Smart prediction of apparent personality traits through Big five from selfies

En este trabajo se presenta un modelo de Inteligencia Artificial basado en Redes Neuronales Profundas para la predicción de personalidad aparente. Es capaz de cuantificar los rasgos de personalidad con el modelo de Five-Factor (Big Five) a partir de una imagen tipo selfie. El modelo fue motivado por la necesidad de medir la personalidad para ser utilizada como criterio de segmentación de clientes y así mejorar el proceso de publicidad dirigida en Marketing, pero no se encuentra limitado a este campo de estudio ya que su alcance se extiende a cualquier proceso que necesite particularizar a un individuo. El modelo utiliza Redes Neuronales Convolucionales para automáticamente extraer características de la selfie que sean indicadores de rasgos de personalidad, después, el modelo clasifica estas características en una clase binaria por cada factor Big Five: apertura a nuevas experiencias, responsabilidad, extraversión, amabilidad e inestabilidad emocional. Los resultados obtenidos muestran que se puede predecir la personalidad utilizando una selfie alcanzando un porcentaje de exactitud similar a los trabajos del estado del arte, obteniendo un 65.86% como clasificador promediando los 5 factores. En comparación con el juicio hecho por un humano, el modelo obtuvo mayor precisión promedio y mayor exactitud en 4 de los 5 factores del modelo Big Five. Además, en comparación con el estado del arte este modelo presenta ciertas ventajas: 1) requiere solo una selfie para hacer la predicción, siendo una selfie un recurso no invasivo y de fácil acceso, 2) la extracción de características de la selfie se hace de manera automática, 3) un único modelo realiza la extracción de características y la clasificación. 

TESIS - 28033 Low Energy DRAM Controller for Computer Systems

“El sistema de memoria: no lo puedes evadir, no lo puedes ignorar, no lo puedes engañar.” Bruce Jacob Las características de desempeño de los sistemas de memoria basados en DRAM son primeramente afectadas por dos atributos: la velocidad de transmisión de datos del dispositivo y el tiempo de ciclo de fila. Las velocidades de transmisión de datos de dispositivos DRAM de productos modernos y los tiempos de ciclo de fila están escalando a diferentes velocidades con cada generación (SDRAM, Open page DRAM, DDR, DDR2, DDR3, DDR4). Como resultado, las características de desempeño de los sistemas de memoria modernos basados en DRAM son cada vez más difíciles de evaluar, y al mismo tiempo la llamada barrera de memoria, la cual señala que la diferencia en el incremento de la frecuencia de reloj de un CPU, y el menor incremento en la velocidad de memoria, limita el desempeño de los sistemas de cómputo actuales, los cuales generalmente acceden a memoria intensivamente. El controlador de memoria es la parte del sistema de memoria principal que está cargo de asegurar el correcto funcionamiento de los dispositivos DRAM, y al mismo tiempo, se encarga de la transmisión de datos hacia y desde los dispositivos DRAM. Sin embargo, dada la complejidad de los protocolos de acceso de memoria DRAM, el gran número de parámetros de tiempo, y el inmenso número de combinaciones de organizaciones de sistemas de memoria, características de cargas de trabajo y diferentes fines de diseño; el diseño de esta parte del sistema de memoria principal en específico tiene tanta libertad de diseño como el diseño de un procesador que implementa la arquitectura de un conjunto de instrucciones en específico. En este trabajo empleamos un simulador de código libre para evaluar diferentes algoritmos de planificación de memoria, lo cual nos permite seleccionar el algoritmo que tiene el mejor desempeño en términos de consumo de energía. Como resultado, proveemos el diseño de la arquitectura de un controlador de memoria, el cual es implementado en Verilog y probado en una plataforma FPGA. Por último, este trabajo provee un análisis profundo de cómo un sistema de memoria basado en DRAM realmente trabaja y qué tan factible es el pasar de un simulador al mundo de la implementación de un controlador de memoria DRAM DDR3.